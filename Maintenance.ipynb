{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_WnihNpOhHSi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/dataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq2kchvduhii",
        "outputId": "be092900-f74c-41dc-acd9-c18773682154"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11934, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#finding duplicates values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjAYYJYLx2Xb",
        "outputId": "7b1f28d7-514d-4dcf-d632-ed54c302800e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "wPtZQqy4lSkf",
        "outputId": "2a07a188-923d-41d6-c93d-d65e1c1eae42"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Lever_position  Ship_speed   shaft_torque  revolutions  Generator  \\\n",
              "0           1.138            3       289.964     1349.489   6677.380   \n",
              "1           2.088            6      6960.180     1376.166   6828.469   \n",
              "2           3.144            9      8379.229     1386.757   7111.811   \n",
              "3           4.161           12     14724.395     1547.465   7792.630   \n",
              "4           5.140           15     21636.432     1924.313   8494.777   \n",
              "\n",
              "   Starboard_ptorque  Port_ptorque   Hight_pressure  Compressor  Turbine  \\\n",
              "0              7.584          7.584         464.006     550.563    1.096   \n",
              "1             28.204         28.204         635.401     581.658    1.331   \n",
              "2             60.358         60.358         606.002     587.587    1.389   \n",
              "3            113.774        113.774         661.471     613.851    1.658   \n",
              "4            175.306        175.306         731.494     645.642    2.078   \n",
              "\n",
              "   air_pressure  gas_pressure  Injecton_control  Fuel_flow  GT_state  \n",
              "0         5.947         1.019             7.137      0.082      0.95  \n",
              "1         7.282         1.019            10.655      0.287      0.95  \n",
              "2         7.574         1.020            13.086      0.259      0.95  \n",
              "3         9.007         1.022            18.109      0.358      0.95  \n",
              "4        11.197         1.026            26.373      0.522      0.95  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f2475283-ac39-4e97-97a2-a06febbc5c97\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lever_position</th>\n",
              "      <th>Ship_speed</th>\n",
              "      <th>shaft_torque</th>\n",
              "      <th>revolutions</th>\n",
              "      <th>Generator</th>\n",
              "      <th>Starboard_ptorque</th>\n",
              "      <th>Port_ptorque</th>\n",
              "      <th>Hight_pressure</th>\n",
              "      <th>Compressor</th>\n",
              "      <th>Turbine</th>\n",
              "      <th>air_pressure</th>\n",
              "      <th>gas_pressure</th>\n",
              "      <th>Injecton_control</th>\n",
              "      <th>Fuel_flow</th>\n",
              "      <th>GT_state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.138</td>\n",
              "      <td>3</td>\n",
              "      <td>289.964</td>\n",
              "      <td>1349.489</td>\n",
              "      <td>6677.380</td>\n",
              "      <td>7.584</td>\n",
              "      <td>7.584</td>\n",
              "      <td>464.006</td>\n",
              "      <td>550.563</td>\n",
              "      <td>1.096</td>\n",
              "      <td>5.947</td>\n",
              "      <td>1.019</td>\n",
              "      <td>7.137</td>\n",
              "      <td>0.082</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.088</td>\n",
              "      <td>6</td>\n",
              "      <td>6960.180</td>\n",
              "      <td>1376.166</td>\n",
              "      <td>6828.469</td>\n",
              "      <td>28.204</td>\n",
              "      <td>28.204</td>\n",
              "      <td>635.401</td>\n",
              "      <td>581.658</td>\n",
              "      <td>1.331</td>\n",
              "      <td>7.282</td>\n",
              "      <td>1.019</td>\n",
              "      <td>10.655</td>\n",
              "      <td>0.287</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.144</td>\n",
              "      <td>9</td>\n",
              "      <td>8379.229</td>\n",
              "      <td>1386.757</td>\n",
              "      <td>7111.811</td>\n",
              "      <td>60.358</td>\n",
              "      <td>60.358</td>\n",
              "      <td>606.002</td>\n",
              "      <td>587.587</td>\n",
              "      <td>1.389</td>\n",
              "      <td>7.574</td>\n",
              "      <td>1.020</td>\n",
              "      <td>13.086</td>\n",
              "      <td>0.259</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.161</td>\n",
              "      <td>12</td>\n",
              "      <td>14724.395</td>\n",
              "      <td>1547.465</td>\n",
              "      <td>7792.630</td>\n",
              "      <td>113.774</td>\n",
              "      <td>113.774</td>\n",
              "      <td>661.471</td>\n",
              "      <td>613.851</td>\n",
              "      <td>1.658</td>\n",
              "      <td>9.007</td>\n",
              "      <td>1.022</td>\n",
              "      <td>18.109</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.140</td>\n",
              "      <td>15</td>\n",
              "      <td>21636.432</td>\n",
              "      <td>1924.313</td>\n",
              "      <td>8494.777</td>\n",
              "      <td>175.306</td>\n",
              "      <td>175.306</td>\n",
              "      <td>731.494</td>\n",
              "      <td>645.642</td>\n",
              "      <td>2.078</td>\n",
              "      <td>11.197</td>\n",
              "      <td>1.026</td>\n",
              "      <td>26.373</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2475283-ac39-4e97-97a2-a06febbc5c97')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f2475283-ac39-4e97-97a2-a06febbc5c97 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f2475283-ac39-4e97-97a2-a06febbc5c97');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-14ed6ef2-52a7-4053-8a7b-82f95cd96331\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-14ed6ef2-52a7-4053-8a7b-82f95cd96331')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-14ed6ef2-52a7-4053-8a7b-82f95cd96331 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11934,\n  \"fields\": [\n    {\n      \"column\": \"Lever_position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6263877188088416,\n        \"min\": 1.138,\n        \"max\": 9.3,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8.206,\n          2.088,\n          6.175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ship_speed \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 3,\n        \"max\": 27,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          24,\n          6,\n          18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shaft_torque\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22148.613154726834,\n        \"min\": 253.547,\n        \"max\": 72784.872,\n        \"num_unique_values\": 11430,\n        \"samples\": [\n          29761.832,\n          29760.421,\n          29791.246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"revolutions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 774.0838812560029,\n        \"min\": 1307.675,\n        \"max\": 3560.741,\n        \"num_unique_values\": 3888,\n        \"samples\": [\n          1346.398,\n          2307.067,\n          1379.711\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Generator\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1091.3155070643115,\n        \"min\": 6589.002,\n        \"max\": 9797.103,\n        \"num_unique_values\": 11834,\n        \"samples\": [\n          8793.252,\n          8511.964,\n          9771.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Starboard_ptorque\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 200.49588925066408,\n        \"min\": 5.304,\n        \"max\": 645.249,\n        \"num_unique_values\": 4286,\n        \"samples\": [\n          175.189,\n          644.768,\n          30.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Port_ptorque \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 200.49588925066408,\n        \"min\": 5.304,\n        \"max\": 645.249,\n        \"num_unique_values\": 4286,\n        \"samples\": [\n          175.189,\n          644.768,\n          30.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hight_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 173.68055215069992,\n        \"min\": 442.364,\n        \"max\": 1115.797,\n        \"num_unique_values\": 11772,\n        \"samples\": [\n          931.869,\n          596.911,\n          588.073\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Compressor\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 72.67588193669337,\n        \"min\": 540.442,\n        \"max\": 789.094,\n        \"num_unique_values\": 11506,\n        \"samples\": [\n          550.157,\n          561.844,\n          583.38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Turbine\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.084769996582546,\n        \"min\": 1.093,\n        \"max\": 4.56,\n        \"num_unique_values\": 524,\n        \"samples\": [\n          2.969,\n          4.534,\n          2.963\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"air_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.337448309242995,\n        \"min\": 5.828,\n        \"max\": 23.14,\n        \"num_unique_values\": 4209,\n        \"samples\": [\n          18.143,\n          6.918,\n          7.197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gas_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010390318528653209,\n        \"min\": 1.019,\n        \"max\": 1.052,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          1.019,\n          1.035,\n          1.036\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Injecton_control\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25.841362973228794,\n        \"min\": 0.0,\n        \"max\": 92.556,\n        \"num_unique_values\": 8496,\n        \"samples\": [\n          12.479,\n          44.887,\n          61.005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fuel_flow\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.507131647280008,\n        \"min\": 0.068,\n        \"max\": 1.832,\n        \"num_unique_values\": 696,\n        \"samples\": [\n          0.837,\n          0.268,\n          0.657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GT_state\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014720218191263438,\n        \"min\": 0.95,\n        \"max\": 1.0,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          0.993,\n          0.99,\n          0.996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "gt_state_counts = df['GT_state'].value_counts()\n",
        "\n",
        "# Print the counts of each unique value in 'GT_state'\n",
        "print(gt_state_counts)\n",
        "\n",
        "# Calculate the percentage of each unique value\n",
        "gt_state_percentages = (gt_state_counts / len(df)) * 100\n",
        "print(gt_state_percentages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ48Vl3Wmx2r",
        "outputId": "60c2c7d5-225e-4888-c839-65b304a6dfed"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GT_state\n",
            "0.950    234\n",
            "0.988    234\n",
            "0.978    234\n",
            "0.979    234\n",
            "0.980    234\n",
            "0.981    234\n",
            "0.982    234\n",
            "0.983    234\n",
            "0.984    234\n",
            "0.985    234\n",
            "0.986    234\n",
            "0.987    234\n",
            "0.989    234\n",
            "0.976    234\n",
            "0.990    234\n",
            "0.991    234\n",
            "0.992    234\n",
            "0.993    234\n",
            "0.994    234\n",
            "0.995    234\n",
            "0.996    234\n",
            "0.997    234\n",
            "0.998    234\n",
            "0.999    234\n",
            "0.977    234\n",
            "0.975    234\n",
            "0.951    234\n",
            "0.962    234\n",
            "0.952    234\n",
            "0.953    234\n",
            "0.954    234\n",
            "0.955    234\n",
            "0.956    234\n",
            "0.957    234\n",
            "0.958    234\n",
            "0.959    234\n",
            "0.960    234\n",
            "0.961    234\n",
            "0.963    234\n",
            "0.974    234\n",
            "0.964    234\n",
            "0.965    234\n",
            "0.966    234\n",
            "0.967    234\n",
            "0.968    234\n",
            "0.969    234\n",
            "0.970    234\n",
            "0.971    234\n",
            "0.972    234\n",
            "0.973    234\n",
            "1.000    234\n",
            "Name: count, dtype: int64\n",
            "GT_state\n",
            "0.950    1.960784\n",
            "0.988    1.960784\n",
            "0.978    1.960784\n",
            "0.979    1.960784\n",
            "0.980    1.960784\n",
            "0.981    1.960784\n",
            "0.982    1.960784\n",
            "0.983    1.960784\n",
            "0.984    1.960784\n",
            "0.985    1.960784\n",
            "0.986    1.960784\n",
            "0.987    1.960784\n",
            "0.989    1.960784\n",
            "0.976    1.960784\n",
            "0.990    1.960784\n",
            "0.991    1.960784\n",
            "0.992    1.960784\n",
            "0.993    1.960784\n",
            "0.994    1.960784\n",
            "0.995    1.960784\n",
            "0.996    1.960784\n",
            "0.997    1.960784\n",
            "0.998    1.960784\n",
            "0.999    1.960784\n",
            "0.977    1.960784\n",
            "0.975    1.960784\n",
            "0.951    1.960784\n",
            "0.962    1.960784\n",
            "0.952    1.960784\n",
            "0.953    1.960784\n",
            "0.954    1.960784\n",
            "0.955    1.960784\n",
            "0.956    1.960784\n",
            "0.957    1.960784\n",
            "0.958    1.960784\n",
            "0.959    1.960784\n",
            "0.960    1.960784\n",
            "0.961    1.960784\n",
            "0.963    1.960784\n",
            "0.974    1.960784\n",
            "0.964    1.960784\n",
            "0.965    1.960784\n",
            "0.966    1.960784\n",
            "0.967    1.960784\n",
            "0.968    1.960784\n",
            "0.969    1.960784\n",
            "0.970    1.960784\n",
            "0.971    1.960784\n",
            "0.972    1.960784\n",
            "0.973    1.960784\n",
            "1.000    1.960784\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in each column\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Print the result\n",
        "print(missing_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH42nEJllUiX",
        "outputId": "6dae08bd-05cf-4dc3-b657-51fd5935b371"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lever_position       0\n",
            "Ship_speed           0\n",
            "shaft_torque         0\n",
            "revolutions          0\n",
            "Generator            0\n",
            "Starboard_ptorque    0\n",
            "Port_ptorque         0\n",
            "Hight_pressure       0\n",
            "Compressor           0\n",
            "Turbine              0\n",
            "air_pressure         0\n",
            "gas_pressure         0\n",
            "Injecton_control     0\n",
            "Fuel_flow            0\n",
            "GT_state             0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def detect_outliers_iqr(data):\n",
        "    Q1 = data.quantile(0.25)\n",
        "    Q3 = data.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    outliers = data[(data < lower_bound) | (data > upper_bound)]\n",
        "    return outliers\n",
        "\n",
        "# Assuming 'df' is your DataFrame\n",
        "numerical_features = df.select_dtypes(include=np.number).columns\n",
        "numerical_features = numerical_features.drop('GT_state')\n",
        "\n",
        "for feature in numerical_features:\n",
        "    outliers = detect_outliers_iqr(df[feature])\n",
        "    outlier_count = len(outliers)\n",
        "    print(f\"Feature: {feature}, Outlier Count: {outlier_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPSJAacemQbp",
        "outputId": "c09f54b1-0014-43ce-8b73-e674a836182b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: Lever_position, Outlier Count: 0\n",
            "Feature: Ship_speed , Outlier Count: 0\n",
            "Feature: shaft_torque, Outlier Count: 0\n",
            "Feature: revolutions, Outlier Count: 0\n",
            "Feature: Generator, Outlier Count: 0\n",
            "Feature: Starboard_ptorque, Outlier Count: 0\n",
            "Feature: Port_ptorque , Outlier Count: 0\n",
            "Feature: Hight_pressure, Outlier Count: 0\n",
            "Feature: Compressor, Outlier Count: 0\n",
            "Feature: Turbine, Outlier Count: 0\n",
            "Feature: air_pressure, Outlier Count: 0\n",
            "Feature: gas_pressure, Outlier Count: 0\n",
            "Feature: Injecton_control, Outlier Count: 192\n",
            "Feature: Fuel_flow, Outlier Count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "df['Injecton_control'] = winsorize(df['Injecton_control'], limits=[0.05, 0.05])"
      ],
      "metadata": {
        "id": "f6qYCJ31vnw9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming you have loaded your dataset into the 'data' DataFrame\n",
        "# Example: data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.iloc[:, :-1].values  # All columns except the target column (features)\n",
        "y = df.iloc[:, -1].values   # The target column (GT_state)\n",
        "\n",
        "# Apply standardization to the input features (excluding the target)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Create a DataFrame for the cleaned, scaled features\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=df.columns[:-1])  # Keep column names for features\n",
        "\n",
        "# Re-add the unscaled target (GT_state) to the cleaned dataset\n",
        "cleaned_data = pd.concat([X_scaled_df, pd.Series(y, name='GT_state')], axis=1)\n",
        "\n",
        "# Save the cleaned dataset to a CSV file\n",
        "cleaned_data.to_csv('cleaned_dataset.csv', index=False)\n",
        "\n",
        "# Download the file to your local system\n",
        "from google.colab import files\n",
        "files.download('cleaned_dataset.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AzWnPg0LzMEW",
        "outputId": "a02e94c3-9a29-4933-8661-d677932f459b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f0ec69ee-3b15-4c7f-bb69-b07c7d5eee7a\", \"cleaned_dataset.csv\", 3312926)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1) get data ready for training\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Load data as DataFrame\n",
        "# Assuming the data is in a CSV file (replace 'pm.csv' with the actual path)\n",
        "data = pd.read_csv('/content/cleaned_dataset.csv')\n",
        "\n",
        "# Separate features and target (first 14 columns are features, the last is the target)\n",
        "X = data.iloc[:, :-1].values  # First 14 columns are input features\n",
        "y = data.iloc[:, -1].values   # Last column is the target variable (GT_state)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the NumPy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)  # Reshape to 2D for PyTorch\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "# Create DataLoader for training and testing data\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "_UggHzrq39eE"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2) built neural network\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a simple linear regression model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LinearRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)  # One input layer, one output\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "# Instantiate the model\n",
        "model = LinearRegressionModel(input_dim=14)\n",
        "\n",
        "# Define the loss function (Mean Squared Error Loss) and the optimizer (Adam)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define hyperparameters\n",
        "num_epochs = 50  # Adjust this based on the complexity of the task\n"
      ],
      "metadata": {
        "id": "RM9FHQ_57hvF"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3) train the model\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()  # Zero out the gradients\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print loss at each epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4CsT4bI8RdK",
        "outputId": "30cd7d62-a69a-440a-a0ea-c5ec211113ed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], Loss: 0.7083\n",
            "Epoch [2/50], Loss: 0.3442\n",
            "Epoch [3/50], Loss: 0.1463\n",
            "Epoch [4/50], Loss: 0.0530\n",
            "Epoch [5/50], Loss: 0.0162\n",
            "Epoch [6/50], Loss: 0.0045\n",
            "Epoch [7/50], Loss: 0.0015\n",
            "Epoch [8/50], Loss: 0.0008\n",
            "Epoch [9/50], Loss: 0.0005\n",
            "Epoch [10/50], Loss: 0.0004\n",
            "Epoch [11/50], Loss: 0.0003\n",
            "Epoch [12/50], Loss: 0.0002\n",
            "Epoch [13/50], Loss: 0.0002\n",
            "Epoch [14/50], Loss: 0.0001\n",
            "Epoch [15/50], Loss: 0.0001\n",
            "Epoch [16/50], Loss: 0.0001\n",
            "Epoch [17/50], Loss: 0.0001\n",
            "Epoch [18/50], Loss: 0.0001\n",
            "Epoch [19/50], Loss: 0.0001\n",
            "Epoch [20/50], Loss: 0.0001\n",
            "Epoch [21/50], Loss: 0.0001\n",
            "Epoch [22/50], Loss: 0.0001\n",
            "Epoch [23/50], Loss: 0.0001\n",
            "Epoch [24/50], Loss: 0.0001\n",
            "Epoch [25/50], Loss: 0.0001\n",
            "Epoch [26/50], Loss: 0.0001\n",
            "Epoch [27/50], Loss: 0.0001\n",
            "Epoch [28/50], Loss: 0.0001\n",
            "Epoch [29/50], Loss: 0.0001\n",
            "Epoch [30/50], Loss: 0.0001\n",
            "Epoch [31/50], Loss: 0.0001\n",
            "Epoch [32/50], Loss: 0.0001\n",
            "Epoch [33/50], Loss: 0.0001\n",
            "Epoch [34/50], Loss: 0.0001\n",
            "Epoch [35/50], Loss: 0.0001\n",
            "Epoch [36/50], Loss: 0.0001\n",
            "Epoch [37/50], Loss: 0.0001\n",
            "Epoch [38/50], Loss: 0.0001\n",
            "Epoch [39/50], Loss: 0.0001\n",
            "Epoch [40/50], Loss: 0.0001\n",
            "Epoch [41/50], Loss: 0.0001\n",
            "Epoch [42/50], Loss: 0.0001\n",
            "Epoch [43/50], Loss: 0.0001\n",
            "Epoch [44/50], Loss: 0.0001\n",
            "Epoch [45/50], Loss: 0.0001\n",
            "Epoch [46/50], Loss: 0.0001\n",
            "Epoch [47/50], Loss: 0.0001\n",
            "Epoch [48/50], Loss: 0.0001\n",
            "Epoch [49/50], Loss: 0.0001\n",
            "Epoch [50/50], Loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4) evaluate the model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Evaluation\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "test_loss = 0.0\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        predictions.extend(outputs.numpy())\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, np.array(predictions)))\n",
        "\n",
        "# Print the average loss and RMSE\n",
        "print(f'Average Test Loss: {test_loss/len(test_loader):.4f}')\n",
        "print(f'RMSE: {rmse:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ8M0TCi8b6S",
        "outputId": "44300baa-ea63-4636-fcb4-acae54fabd9b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Test Loss: 0.0001\n",
            "RMSE: 0.0078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Define the improved model with dropout\n",
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, dropout_rate):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
        "        self.fc3 = nn.Linear(hidden_dim2, 1)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Wrapper class to integrate with sklearn's GridSearchCV\n",
        "class PyTorchModelWrapper:\n",
        "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, dropout_rate):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.model = ImprovedModel(input_dim, hidden_dim1, hidden_dim2, dropout_rate)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.optimizer = None\n",
        "\n",
        "    # Required for GridSearchCV to retrieve model parameters\n",
        "    def get_params(self, deep=True):\n",
        "        return {\n",
        "            'input_dim': self.input_dim,\n",
        "            'hidden_dim1': self.hidden_dim1,\n",
        "            'hidden_dim2': self.hidden_dim2,\n",
        "            'dropout_rate': self.dropout_rate\n",
        "        }\n",
        "\n",
        "    # Required for GridSearchCV to set model parameters\n",
        "    def set_params(self, **params):\n",
        "        for param, value in params.items():\n",
        "            setattr(self, param, value)\n",
        "        # Re-initialize the model with updated parameters\n",
        "        self.model = ImprovedModel(self.input_dim, self.hidden_dim1, self.hidden_dim2, self.dropout_rate)\n",
        "        return self\n",
        "\n",
        "    # Training function\n",
        "    def fit(self, X, y, epochs=100, batch_size=64):\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1)  # Reshape y to 2D for PyTorch\n",
        "        dataset = TensorDataset(X_tensor, y_tensor)\n",
        "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters())\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            for inputs, targets in dataloader:\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "    # Prediction function\n",
        "    def predict(self, X):\n",
        "        X_tensor = torch.tensor(X, dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            return self.model(X_tensor).numpy()\n",
        "\n",
        "# Load your cleaned data\n",
        "data = pd.read_csv('/content/cleaned_dataset.csv')\n",
        "X = data.iloc[:, :-1].values  # Input features\n",
        "y = data.iloc[:, -1].values   # Target variable (GT_state)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'hidden_dim1': [64, 128, 256],\n",
        "    'hidden_dim2': [32, 64, 128],\n",
        "    'dropout_rate': [0.1, 0.2, 0.3],\n",
        "}\n",
        "\n",
        "# Create the model wrapper for GridSearchCV\n",
        "model_wrapper = PyTorchModelWrapper(input_dim=X_train.shape[1], hidden_dim1=128, hidden_dim2=64, dropout_rate=0.2)\n",
        "\n",
        "# Create GridSearchCV object\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model_wrapper,\n",
        "    param_grid=param_grid,\n",
        "    scoring='neg_mean_squared_error',  # Use negative MSE for regression\n",
        "    cv=5,  # 5-fold cross-validation\n",
        "    n_jobs=-1,  # Use all available processors\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score (Negative MSE):\", best_score)\n",
        "\n",
        "# Evaluate the model with the best parameters on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)  # Predict on the test set\n",
        "\n",
        "# Calculate RMSE on the test set\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f'RMSE on Test Set: {rmse:.4f}')\n"
      ],
      "metadata": {
        "id": "B9j78bWR47hp"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5) improve the model with experiments\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Define the improved model\n",
        "class ImprovedModel(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(ImprovedModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)  # Increased hidden units\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 1)\n",
        "        self.dropout = nn.Dropout(0.2)  # Added dropout for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply dropout after activation\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "# Instantiate the improved model\n",
        "improved_model = ImprovedModel(input_dim=14)\n",
        "optimizer = torch.optim.Adam(improved_model.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100  # Increased epochs\n",
        "batch_size = 64  # Adjusted batch size\n",
        "\n",
        "train_dataset = TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    improved_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = improved_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "# Evaluation\n",
        "improved_model.eval()\n",
        "test_loss = 0.0\n",
        "predictions = []\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32).unsqueeze(1))\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        outputs = improved_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        test_loss += loss.item()\n",
        "        predictions.extend(outputs.numpy())\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, np.array(predictions)))\n",
        "\n",
        "print(f'Average Test Loss: {test_loss/len(test_loader):.4f}')\n",
        "print(f'RMSE: {rmse:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rt7eUOpiqXmK",
        "outputId": "22a04f1f-1793-4e11-8613-1fef59751646"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.0744\n",
            "Epoch [2/100], Loss: 0.0140\n",
            "Epoch [3/100], Loss: 0.0117\n",
            "Epoch [4/100], Loss: 0.0103\n",
            "Epoch [5/100], Loss: 0.0096\n",
            "Epoch [6/100], Loss: 0.0082\n",
            "Epoch [7/100], Loss: 0.0075\n",
            "Epoch [8/100], Loss: 0.0068\n",
            "Epoch [9/100], Loss: 0.0061\n",
            "Epoch [10/100], Loss: 0.0054\n",
            "Epoch [11/100], Loss: 0.0049\n",
            "Epoch [12/100], Loss: 0.0043\n",
            "Epoch [13/100], Loss: 0.0039\n",
            "Epoch [14/100], Loss: 0.0036\n",
            "Epoch [15/100], Loss: 0.0032\n",
            "Epoch [16/100], Loss: 0.0029\n",
            "Epoch [17/100], Loss: 0.0026\n",
            "Epoch [18/100], Loss: 0.0024\n",
            "Epoch [19/100], Loss: 0.0021\n",
            "Epoch [20/100], Loss: 0.0019\n",
            "Epoch [21/100], Loss: 0.0017\n",
            "Epoch [22/100], Loss: 0.0015\n",
            "Epoch [23/100], Loss: 0.0014\n",
            "Epoch [24/100], Loss: 0.0012\n",
            "Epoch [25/100], Loss: 0.0011\n",
            "Epoch [26/100], Loss: 0.0009\n",
            "Epoch [27/100], Loss: 0.0008\n",
            "Epoch [28/100], Loss: 0.0007\n",
            "Epoch [29/100], Loss: 0.0006\n",
            "Epoch [30/100], Loss: 0.0005\n",
            "Epoch [31/100], Loss: 0.0004\n",
            "Epoch [32/100], Loss: 0.0004\n",
            "Epoch [33/100], Loss: 0.0003\n",
            "Epoch [34/100], Loss: 0.0003\n",
            "Epoch [35/100], Loss: 0.0002\n",
            "Epoch [36/100], Loss: 0.0002\n",
            "Epoch [37/100], Loss: 0.0002\n",
            "Epoch [38/100], Loss: 0.0001\n",
            "Epoch [39/100], Loss: 0.0001\n",
            "Epoch [40/100], Loss: 0.0001\n",
            "Epoch [41/100], Loss: 0.0001\n",
            "Epoch [42/100], Loss: 0.0001\n",
            "Epoch [43/100], Loss: 0.0001\n",
            "Epoch [44/100], Loss: 0.0001\n",
            "Epoch [45/100], Loss: 0.0001\n",
            "Epoch [46/100], Loss: 0.0001\n",
            "Epoch [47/100], Loss: 0.0001\n",
            "Epoch [48/100], Loss: 0.0001\n",
            "Epoch [49/100], Loss: 0.0001\n",
            "Epoch [50/100], Loss: 0.0001\n",
            "Epoch [51/100], Loss: 0.0001\n",
            "Epoch [52/100], Loss: 0.0000\n",
            "Epoch [53/100], Loss: 0.0000\n",
            "Epoch [54/100], Loss: 0.0000\n",
            "Epoch [55/100], Loss: 0.0000\n",
            "Epoch [56/100], Loss: 0.0000\n",
            "Epoch [57/100], Loss: 0.0000\n",
            "Epoch [58/100], Loss: 0.0000\n",
            "Epoch [59/100], Loss: 0.0000\n",
            "Epoch [60/100], Loss: 0.0000\n",
            "Epoch [61/100], Loss: 0.0000\n",
            "Epoch [62/100], Loss: 0.0000\n",
            "Epoch [63/100], Loss: 0.0000\n",
            "Epoch [64/100], Loss: 0.0000\n",
            "Epoch [65/100], Loss: 0.0000\n",
            "Epoch [66/100], Loss: 0.0000\n",
            "Epoch [67/100], Loss: 0.0000\n",
            "Epoch [68/100], Loss: 0.0000\n",
            "Epoch [69/100], Loss: 0.0000\n",
            "Epoch [70/100], Loss: 0.0000\n",
            "Epoch [71/100], Loss: 0.0000\n",
            "Epoch [72/100], Loss: 0.0000\n",
            "Epoch [73/100], Loss: 0.0000\n",
            "Epoch [74/100], Loss: 0.0000\n",
            "Epoch [75/100], Loss: 0.0000\n",
            "Epoch [76/100], Loss: 0.0000\n",
            "Epoch [77/100], Loss: 0.0000\n",
            "Epoch [78/100], Loss: 0.0000\n",
            "Epoch [79/100], Loss: 0.0000\n",
            "Epoch [80/100], Loss: 0.0000\n",
            "Epoch [81/100], Loss: 0.0000\n",
            "Epoch [82/100], Loss: 0.0000\n",
            "Epoch [83/100], Loss: 0.0000\n",
            "Epoch [84/100], Loss: 0.0000\n",
            "Epoch [85/100], Loss: 0.0000\n",
            "Epoch [86/100], Loss: 0.0000\n",
            "Epoch [87/100], Loss: 0.0000\n",
            "Epoch [88/100], Loss: 0.0000\n",
            "Epoch [89/100], Loss: 0.0000\n",
            "Epoch [90/100], Loss: 0.0000\n",
            "Epoch [91/100], Loss: 0.0000\n",
            "Epoch [92/100], Loss: 0.0000\n",
            "Epoch [93/100], Loss: 0.0000\n",
            "Epoch [94/100], Loss: 0.0000\n",
            "Epoch [95/100], Loss: 0.0000\n",
            "Epoch [96/100], Loss: 0.0000\n",
            "Epoch [97/100], Loss: 0.0000\n",
            "Epoch [98/100], Loss: 0.0000\n",
            "Epoch [99/100], Loss: 0.0000\n",
            "Epoch [100/100], Loss: 0.0000\n",
            "Average Test Loss: 0.0000\n",
            "RMSE: 0.0024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fttZBJ9c2AxZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}